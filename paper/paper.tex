\documentclass[letterpaper,11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{geometry}
\usepackage{bussproofs}
\usepackage{listings}
\usepackage{simplebnf}

\newgeometry{vmargin={18mm}, hmargin={20mm}}

\newcommand{\D}{\mathcal{D}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\mtt}[1]{\mathtt{#1}}

\title{borrow-lambda}
\author{Taran Dwivedula, Jeff Zhang}

\begin{document}

\maketitle

\begin{abstract}
    Borrow checking and ownership is a solution to many of the problems that commonly arise in programming languages with manual memory management like C.
    Like the strategy of garbage collection implemented in several common general purpose programming languages, borrow checking eliminates the
    need for programmers to manually allocate and free the memory their program uses, which is the source of many human errors in programming.
    However, the need for high performance code makes garbage collection a sub-optimal solution, as garbage collection introduces performance
    overheads, non-determinism, and potentially memory fragmentation. Borrow checking and ownership is an alternative that takes a different
    approach - it relies on the strength of the programming language's typesystem. It is a set of rules that allows the compiler to
    automatically determine where to allocate and free memory, both eliminating the need of a garbage collector and the need for a programmer
    to manually allocate and free memory. In this paper, we discuss borrow checking as a solution to common memory errors, and provide
    and implementation on a small extension of the simply-typed lambda calculus.
\end{abstract}

\section{Introduction}
Systems-level programming mandates high performance code; that is, code that runs with minimal overhead, and uses memory efficiently. Minimizing
fragmentation on the heap is essential, especially for servers and embedded systems. It's why a programming language like C has been very popular
in this domain for decades. C is an abstraction directly from assembly that was
designed to make code easier to read and write. As such, control of heap allocated
memory remains fully with the programmer. The practice of writing good and safe code
is left to the programmer - the idea being, a skilled programmer would be able to write
memory safe code without mistakes, and just like assembly, mistakes would not result
in errors - just undefined behaviour.

Over time, we have seen that relying on programmers to be skilled enough to avoid
making memory errors in their code is not feasible. When codebases become large scale,
these errors become extremely hard to avoid. Computer viruses and exploits due to
things like buffer overflows affect many people and are still present in a large
amount of software today.

For general purpose programming, the concept of a garbage collector was able to solve
this problem. A garbage collector finds areas of memory that are no longer referenced
at some point in the program, and frees the memory. Different strategies exist, such
as reference counting, stop and copy, and mark and sweep strategies. Usually, the
garbage collector is required to run as a separate process, adding performance
overhead. Some strategies of garbage collection allow the garbage collector to run
concurrent to the program, but fragment the memory. Other strategies avoid memory
fragmentation, but require the running program to be paused so the memory can be
copied over in a non-fragmented fashion. In any case, garbage collection results
in the overhead of another process, as well as sometimes non-determinism in the layout
of memory, both of which are extremely sub-optimal for high performance systems code.

Work has been done to improve manually memory managed languages like C in terms of
safety, by strenghthening the typesystem itself, and attacking the semantics of the
language. Cyclone, a Cornell lab project, developed a dialect of C that works to
ensure memory safety at compile time. Among the features included were statically
checked lifetimes of pointer variables, and restrictions on types of pointers which
work to ensure safety with regards to multi-aliasing (add citation). Similarly, the
concept of ownership types was conceived as a software design principle, particularly
in research on concurrent programming, where an object governs an area of memory,
and administers any modifications to it (add citations). In the modern day,
many of these features were materialized in the Rust programming language, a popular
systems-level programming language that is making the case for the assistance of
borrow checking and ownership for high performance code.

In this paper, we implement borrow checking and ownership on a small extension of the
simply typed lambda calculus. The paper is organized as follows. Section 2 provides an
overview of the components of the borrow checking and ownership strategy. Section 3
discusses our implementation of a borrow checker in \texttt{borrow-lambda}.
Section 4 describes some of the main challenges we faced when developing this
implementation, and our solutions to them. Section 5 concludes the discussion
of our implementation and discusses potential further improvements. Section 6
gives an overview of related work in the literature.

\section{Overview}
The borrow checking and ownership strategy can be divided into three separate components
that work together - Ownership, Borrowing, and Lifetimes. This section will conceptually
describe the three. As the Rust programming language is the most well known widespread
implementation of these concepts, we will reference it for illustrative purposes.

\subsection{Ownership}
Rust implements ownership as described with three main rules (add citation).
\begin{itemize}
    \item Each value in Rust has an owner.
    \item There can only be one owner at a time.
    \item When the owner goes out of scope, the value will be dropped.
\end{itemize}
In reality, this is an instance of an \textit{affine type system} - an instance
of a substructural type system based on substructural logic where the rule
of contraction is not permitted. In code, this corresponds to the language's
move semantics - if a value isn't given the ability to be copied, it is instead
\textit{moved}. Ownership and scope of the value is transferred to the new binder.
This allows the compiler to statically determine where the memory of the value
should be freed, and where the value, as well as names tied to it, are allowed to
be used, absolving this responsibility from the programmer.
\begin{figure}[h]
    \begin{lstlisting}
        fn main() {
            let nums = vec![1, 2, 3];

            do_something_with_vec(nums);
            do_something_with_vec(nums);  // error
        }

        fn do_something_with_vec(v: Vec<u32>) {}
    \end{lstlisting}

    \caption{Example Rust code illustrating move semantics}
    \label{ms}
\end{figure}
Figure \ref{ms} illustrates an example. We create a vector of unsigned
integers - an object whose type does not permit copying - and bind it to the
variable \texttt{nums}. We say the variable \texttt{nums} \textit{owns} this
vector and its associated memory. Up to this point, we should expect \texttt{nums}
to go out of scope at the end of \texttt{main}, and the compiler would automatically
free the memory at this time. However, we instead pass \texttt{nums} as a parameter
into the function \texttt{do\_something\_with\_vec}. Then, as previously described,
the vector gets \textit{moved} into \texttt{do\_something\_with\_vec}. The vector is
no longer bound to the name \texttt{nums}, which causes the second call to
\texttt{do\_something\_with\_vec} to fail. Additionally, as the new owner, the
function call administers the scope of this vector as well. As such, the vector's
memory gets freed at the end of the function call. At this point, all access points to this memory are unusable and trigger compile time errors, which is what we want.

What if we did actually want to use the same vector twice inside of \texttt{main}?
Currently, it is quite inconvenient that the vector gets detached from the \texttt{nums}
variable after the first use of it. We may rewrite the code such that
\texttt{do\_something\_with\_vec} returns the vector, passing ownership of it back
to the caller, allowing us to re-bind the vector to the \texttt{nums} variable.
That is one possible solution, but what we really want is to provide some sort
of reference, rather than temporarily giving ownership and taking it back.
Crucially, it eliminates one nice guarantee we can make, which is the state
of the value before and after we lend it. It would be nice to know, at a type level,
whether the value we lent was mutated before we received it back. This is made
possible with borrowing, which we describe in the next subsection.

\subsection{Borrowing}
Borrowing is a form of restricted pointers that allows us to give access of a value
in memory, without relinquishing ownership of the value. Access is given through
references to the value. These references are set to be either immutable or mutable
by the programmer, meaning that references may only provide a view on the data
without providing permission to mutate the data. Enforcement is an easy check during
compile time.

The concept of mutable and immutable references is simple enough, but what makes them
useful is the rules that determine when they are valid, and how they affect the
access points of memory. Particularly, the following rules related to references
are enforced at compile time.
\begin{itemize}
    \item At any given time, a value can have either one mutable reference pointing to it, or any amount of immutable references pointing to it, but not both.
    \item The owner of a value cannot mutate or give up ownership of a value while any references to the value are in scope.
\end{itemize}
Again, both easy checks at compile time. It is easily seen that these two restrictions
ensure two important conditions, that is, only one object is able to mutate a value
at a time, and that values will not be mutated or freed while being read from. In
other words, this eliminates the problem of mutable aliasing.

\subsection{Lifetimes}
It is important to know how long a value is valid for, before its associated memory
is freed or repurposed. Being able to check this at compile time is a large component
of creating a memory safe language. The aformentioned Cyclone first experimented
with this by adding regions to C, and it is the basis of Rust's lifetimes feature.
A potential, and extremely common error, is that we may have a pointer to some value
that we continue to use even after the value's associated memory gets freed - a dangling pointer.

With the groundwork of ownership and borrowing laid out, the solution to this is
simple - when we borrow a value, we must ensure that the value's associated memory
does not get freed while a reference to it is still in scope. Or rather, we should
not allow a reference to be created if its scope exceeds the window for which
the value's memory remains intact. We formalize this with lifetimes.

Generally, the \textit{lifetime} of a value, or the window in which its memory
can be used before it is freed, is taken from the scope of its owner. These
lifetimes are embedded into the typesystem as any references are additionally
tagged with the lifetime of the value it is pointing to. Then, these references
are checked with a subtyping relation, where a reference with a larger scope
is a subtype of a reference with a smaller scope. This allows us to check that
all borrows, or references, go out of scope before the value that they are borrowing
is freed.

\texttt{TODO: maybe add example code, explanation for functions polymorphic over lifetimes}

\section{Implementation}
Our implementation consists of a small extension to the simply-typed lambda calculus,
with constructs that are both necessary and illustrative to borrow checking and ownership,
as well as the typing rules that facilitate borrow checking and ownership. The
implementation is written in OCaml, with each of the constructs encoded as
OCaml types. The main relevant component is the typechecker, which runs in two
phases that will be described in this section. Additionally, we have included a
parser which collects source code into terms represented as nodes in an abstract syntax tree, and an evaluator in order to develop a fully functional REPL.

\subsection{Syntax}
Our syntax of terms is as follows.
\begin{center}
    \begin{bnf}
        $t$ : \textsf{Term} ::=
        | $x$ | $\lambda x\ldotp t$ | $t_1\ t_2$ | $\&x$ | $\&\text{mut}\ x$ | $*x$
        | if $t_1$ then $t_2$ else $t_3$
        | let $x = t_1$ in $t_2$
        | $x \coloneq t$
        | $*x \coloneq t$
        | true
        | false
        | unit
        | 0
        | pred $t$
        | succ $t$
        | iszero $t$
        | natvec($t_1,t_2,\dots t_n$)
        | get($t_1,t_2$)
        | getmut($t_1,t_2$)
        | push($t_1,t_2$)
        | pop($t_1$) 
    \end{bnf}
\end{center}
In addition to standard nats and bools and some simple operations for them, we add
mutable and immutable references, the dereference operator, assignment and
dereference-assignment, as well as a vector of nats for a more complex
(non-copyable) data structure. We add terms representing operations that
create a a vector given a list of terms, get a reference (mutable or immutable)
of an element of a vector given a reference to the vector and an index, a similar
method for pushing an element to a vector, and a method for popping an element
(and returning the actual element as opposed to just a reference of it). Note that
in this implementation, all variables are mutable.

For the syntax of types, we first introduce a couple of constructs that will make
them up.
\begin{center}
    \begin{bnf}
        $\kappa$ : \textsf{Lifetime} ::= $\alpha$
    \end{bnf}

    \begin{bnf}
        $\mu$ : \textsf{Mod} ::= mut | shr
    \end{bnf}
\end{center}
Lifetimes are represented by numeric values, corresponding to their scope depth.
We can make this definition, as each binding site introduces a new scope. The
subtyping relation works by then considering a reference with a larger lifetime variable a subtype
of a reference with a smaller lifetime variable. The mod corresponds to the type
of reference (mutable or shared, i.e. immutable). The types of references will be
annotated with both of these constructs, in addition to a type.

We distinguish types that aren't themselves references as a subset of all types.
This helps with reasoning about typing rules in certain cases where
checking rules differ slightly based on this.
\begin{center}
    \begin{bnf}
        $T_*$ : \textsf{Non-Reference Types} ::=
        | Nat | Bool | Unit | $\forall\alpha.T_1\rightarrow T_2$ | NatVec
    \end{bnf}
    
    \begin{bnf}
        $T$ : \textsf{Types} ::=
        | $\&^\kappa_\mu T$ | $T_*$
    \end{bnf}
\end{center}

Lastly, when relevant, our typing rules make use of the following named set,
denoting types that are copyable.
$$\text{Copy}=\{\text{Nat}, \text{Bool}, \text{Unit},\&^\kappa_{\text{shr}} T\}$$

\subsection{Typechecking Pass}
We use bidirectional typechecking, as we felt that this was the simplest and
most natural solution, especially for terms like the if clause whose type depends
on that of the sub terms. As expected, the typechecker checks that terms are
well-typed, and annotates the corresponding abstract syntax tree node with
the determined type of the node, generating a new abstract syntax tree with nodes
annotated with their types.

This pass also does all the necessary work for lifetimes; assigning lifetimes
to each of the variables and their respective borrows, checking the subtype
relation of lifetimes, and handling instantiation of functions polymorphic over
lifetimes.

\texttt{TODO: add code examples and rules}

\subsection{Borrow Checking Pass}
The borrow checking pass is responsible for checking rules related to ownership
and borrowing.
Firstly, it checks the affine type property - that no value is used more than once.
This is done by maintaining a context of variable usages which we call $\Delta$. Depending on if the type
of the value is copyable, the variable gets added to this set. For a copyable variable,
we don't need to track its usage for the purpose of validating move semantics.
Additionally, we check that variables cannot be moved while being borrowed, by
maintaining a context of the current borrows, which we call $B$. This is encoded
in the following typing rule.
$$\frac{\Gamma(x) = T \quad x \not\in \Delta \quad T \not\in \text{Copy} \quad x_{\mu} \not\in B}{\Gamma \mid B \mid \Delta \vdash x : T \mid \Delta, x}$$
A couple of interesting special cases include the handling of if statements,
and providing the ability to assign a value to a variable that has had a value
moved out of it. In the former case, we will output the union of both $\Delta$
contexts generated by traversing each branch of the if statement. In the latter case,
we remove the current variable from the $\Delta$ context when assigning it a value
if it is present, so that it can be used again, as seen in the following rule.
$$\frac{\Gamma \mid \Delta \mid B \vdash t :  T \mid \Delta' \quad \Gamma(x) = T \quad x_{\mu} \not\in B}{\Gamma \mid \Delta \mid B \vdash x := t : \text{Unit} \mid \Delta' \setminus x}$$
The borrow checking pass also uses the $B$ context to check that borrows adhere to
the mutability rule, that is, mutable borrows can't exist while any other borrow
to the same value is in scope, and immutable borrows can't exist while a mutable
borrow to the same value is in scope.
Finally, this pass also checks that references themselves are valid with respect
to their lifetimes. This could potentially arise if an escaping reference is returned
out of a let in or lambda statement. We make use of the lifetime annotations from
the previous pass, and ensure that these references being returned out have
larger lifetime than the scope they are being returned to. The following rule,
though quite complex, encodes this.
$$\frac{\Gamma \mid F \mid \Delta \mid B \vdash t_{1} : T_{1} \mid \Delta_{1} \mid B_{1} \quad \Gamma,x : T_{1} ; |\Gamma| \mid F,x \mid \Delta_{1} \mid B_{1} \vdash t_{2} : \&^{\beta}_{\mu} T_{2} \mid \Delta_{2} \mid B_{2} \quad \beta < |\Gamma|}{\Gamma \mid F \mid \Delta \mid B \vdash \text{let $x = t_{1}$ in $t_{2}$} : \&^{\beta}_{\mu}\ T_{2} \mid \Delta_{2} \mid B}$$
We introduce the fourth context here - $F$, which tracks variables bound in the current
scope of the let in or lambda closure. Additionally, we use the semicolon as a shorthand
to retrieve both a variable's type (on the left) and lifetime (on the right) from
the $\Gamma$ (variables) context together. The rule states that
when a reference is returned out with lifetime $\beta$, the program typechecks
if the current scope of the closure, which is reflected by the lifetime variable
of bound variable $x$, is smaller than the scope of the reference that is being
returned out from. This means that the reference that is being returned out of
the closure outlives the closure itself, which is what we want.

\section{Challenges}

\section{Conclusion and Future Work}

\section{Related Work}

\end{document}
